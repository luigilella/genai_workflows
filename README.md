# genai_workflows
This repository contains KNIME workflow examples demonstrating how Generative AI and Large Language Models (LLMs) can be safely and effectively used to support typical public administration activities. The proposed use cases focus on efficiency, transparency, GDPR compliance and human oversight, in line with European regulatory and ethical principles.
All workflows presented in this repository rely exclusively on Generative AI models deployed locally via the Ollama platform (https://ollama.com/).
This architectural choice ensures full control over data, prevents unintended data disclosure to external providers, and supports compliance with GDPR and public sector security requirements.

Use Case #1 – Sentiment Analysis with LLMs
This use case represents one of the earliest and most common applications of LLMs: sentiment analysis of user or citizen feedback, complaints and reports.
The workflow automatically analyses textual inputs to classify sentiment and produces structured reports. These reports may include charts showing sentiment distribution and its evolution over time, supporting monitoring, service quality assessment and evidence-based decision-making.

Use Case #3 – Internal Report Generation with Local LLMs
Generating internal reports from potentially strategic, personal or sensitive data cannot rely on external online LLM services provided by major vendors, as prompts and data may be reused for model retraining.
To ensure full GDPR compliance, this workflow uses locally deployed LLMs. This approach prevents data leakage and allows fine-grained control over model behaviour by adjusting parameters such as temperature and top-p, enabling more factual or more creative outputs depending on the use case.

Use Case #4 – Internal Report Generation with Reference Documentation (RAG)
This use case applies Retrieval-Augmented Generation (RAG) using the “gpt-oss” LLM. Reports are generated by constraining the model’s responses to the content of an internal organisational knowledge base.
This ensures that outputs remain aligned with official documentation, policies and procedures, improving accuracy, traceability and trustworthiness while reducing hallucinations.
